{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from games.leduc import Leduc\n",
    "from agents.agent_random import RandomAgent\n",
    "from agents.counterfactualregret import CounterFactualRegret\n",
    "from base.utils import play, run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "game = Leduc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "player_0 Dict('action_mask': Box(0, 1, (4,), int8), 'observation': Box(0.0, 1.0, (36,), float32))\n",
      "player_1 Dict('action_mask': Box(0, 1, (4,), int8), 'observation': Box(0.0, 1.0, (36,), float32))\n"
     ]
    }
   ],
   "source": [
    "for agent in game.agents:\n",
    "    print(agent, game.observation_space(agent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "player_0 Discrete(4)\n",
      "player_1 Discrete(4)\n"
     ]
    }
   ],
   "source": [
    "for agent in game.agents:\n",
    "    print(agent, game.action_space(agent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "agents = dict(map(lambda p: (p, RandomAgent(game=game, agent=p)), game.agents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=============== player_0's Hand ===============\n",
      "┌─────────┐\n",
      "│Q        │\n",
      "│         │\n",
      "│         │\n",
      "│    ♥    │\n",
      "│         │\n",
      "│         │\n",
      "│        Q│\n",
      "└─────────┘\n",
      "\n",
      "player_0's Chips: 2\n",
      "\n",
      "=============== player_1's Hand ===============\n",
      "┌─────────┐\n",
      "│J        │\n",
      "│         │\n",
      "│         │\n",
      "│    ♥    │\n",
      "│         │\n",
      "│         │\n",
      "│        J│\n",
      "└─────────┘\n",
      "\n",
      "player_1's Chips: 1\n",
      "\n",
      "================= Public Cards =================\n",
      "No public cards.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "game.reset()\n",
    "game.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "player_0 {'hand': 'SK', 'public_card': None, 'all_chips': [2, 1], 'my_chips': 2, 'legal_actions': ['call', 'raise', 'fold'], 'current_player': 1}\n",
      "player_1 {'hand': 'SQ', 'public_card': None, 'all_chips': [2, 1], 'my_chips': 1, 'legal_actions': ['call', 'raise', 'fold'], 'current_player': 1}\n",
      "player_1 obs= Q_#_2_1_1 action= k\n",
      "{'player_0': 0.5, 'player_1': -0.5}\n"
     ]
    }
   ],
   "source": [
    "game.reset()\n",
    "for agent in game.agents:\n",
    "    state = game.env.env.game.get_state(game.env._name_to_int(agent))\n",
    "    print(agent, state)\n",
    "while not game.terminated():\n",
    "    player = game.agent_selection\n",
    "    action = agents[player].action()\n",
    "    print(player, 'obs=', game.observe(player), 'action=', game._moves[action])\n",
    "    #game.render()\n",
    "    game.step(action)\n",
    "print(game.rewards)\n",
    "#game.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=============== player_0's Hand ===============\n",
      "┌─────────┐\n",
      "│Q        │\n",
      "│         │\n",
      "│         │\n",
      "│    ♥    │\n",
      "│         │\n",
      "│         │\n",
      "│        Q│\n",
      "└─────────┘\n",
      "\n",
      "player_0's Chips: 2\n",
      "\n",
      "=============== player_1's Hand ===============\n",
      "┌─────────┐\n",
      "│K        │\n",
      "│         │\n",
      "│         │\n",
      "│    ♠    │\n",
      "│         │\n",
      "│         │\n",
      "│        K│\n",
      "└─────────┘\n",
      "\n",
      "player_1's Chips: 1\n",
      "\n",
      "================= Public Cards =================\n",
      "No public cards.\n",
      "\n",
      "\n",
      "\n",
      "=============== player_0's Hand ===============\n",
      "┌─────────┐\n",
      "│Q        │\n",
      "│         │\n",
      "│         │\n",
      "│    ♥    │\n",
      "│         │\n",
      "│         │\n",
      "│        Q│\n",
      "└─────────┘\n",
      "\n",
      "player_0's Chips: 6\n",
      "\n",
      "=============== player_1's Hand ===============\n",
      "┌─────────┐\n",
      "│K        │\n",
      "│         │\n",
      "│         │\n",
      "│    ♠    │\n",
      "│         │\n",
      "│         │\n",
      "│        K│\n",
      "└─────────┘\n",
      "\n",
      "player_1's Chips: 4\n",
      "\n",
      "================= Public Cards =================\n",
      "No public cards.\n",
      "\n",
      "\n",
      "{'player_0': 2.0, 'player_1': -2.0}\n"
     ]
    }
   ],
   "source": [
    "TRAIN_ITER = 5000\n",
    "cfr_agent = CounterFactualRegret(game=game, agent=game.agents[0])\n",
    "cfr_agent.train(niter=TRAIN_ITER)\n",
    "agents[game.agents[0]] = cfr_agent\n",
    "play(game=game, agents=agents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=============== player_0's Hand ===============\n",
      "┌─────────┐\n",
      "│J        │\n",
      "│         │\n",
      "│         │\n",
      "│    ♠    │\n",
      "│         │\n",
      "│         │\n",
      "│        J│\n",
      "└─────────┘\n",
      "\n",
      "player_0's Chips: 1\n",
      "\n",
      "=============== player_1's Hand ===============\n",
      "┌─────────┐\n",
      "│K        │\n",
      "│         │\n",
      "│         │\n",
      "│    ♠    │\n",
      "│         │\n",
      "│         │\n",
      "│        K│\n",
      "└─────────┘\n",
      "\n",
      "player_1's Chips: 2\n",
      "\n",
      "================= Public Cards =================\n",
      "No public cards.\n",
      "\n",
      "\n",
      "\n",
      "=============== player_0's Hand ===============\n",
      "┌─────────┐\n",
      "│J        │\n",
      "│         │\n",
      "│         │\n",
      "│    ♠    │\n",
      "│         │\n",
      "│         │\n",
      "│        J│\n",
      "└─────────┘\n",
      "\n",
      "player_0's Chips: 4\n",
      "\n",
      "=============== player_1's Hand ===============\n",
      "┌─────────┐\n",
      "│K        │\n",
      "│         │\n",
      "│         │\n",
      "│    ♠    │\n",
      "│         │\n",
      "│         │\n",
      "│        K│\n",
      "└─────────┘\n",
      "\n",
      "player_1's Chips: 4\n",
      "\n",
      "================= Public Cards =================\n",
      "┌─────────┐\n",
      "│Q        │\n",
      "│         │\n",
      "│         │\n",
      "│    ♥    │\n",
      "│         │\n",
      "│         │\n",
      "│        Q│\n",
      "└─────────┘\n",
      "\n",
      "\n",
      "{'player_0': 2.0, 'player_1': -2.0}\n"
     ]
    }
   ],
   "source": [
    "cfr_agent = CounterFactualRegret(game=game, agent=game.agents[1])\n",
    "cfr_agent.train(niter=TRAIN_ITER)\n",
    "agents[game.agents[1]] = cfr_agent\n",
    "play(game=game, agents=agents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Train agent before calling action()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/Downloads/MA/AlternatingGames/agents/counterfactualregret.py:60\u001b[0m, in \u001b[0;36mCounterFactualRegret.action\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 60\u001b[0m     node \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnode_dict[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgame\u001b[39m.\u001b[39;49mobserve(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49magent)]\n\u001b[1;32m     61\u001b[0m     a \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmax(np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mmultinomial(\u001b[39m1\u001b[39m, node\u001b[39m.\u001b[39mpolicy(), size\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m))\n",
      "\u001b[0;31mKeyError\u001b[0m: 'K_#_1_2_0'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/fazzato/Downloads/MA/AlternatingGames/CFR_Leduc.ipynb Cell 11\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/fazzato/Downloads/MA/AlternatingGames/CFR_Leduc.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Si falla al ejecutar con el error que hay que entrenar primero, hay que entrenar por más iteraciones\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/fazzato/Downloads/MA/AlternatingGames/CFR_Leduc.ipynb#X13sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m run(game\u001b[39m=\u001b[39;49mgame, agents\u001b[39m=\u001b[39;49magents)\n",
      "File \u001b[0;32m~/Downloads/MA/AlternatingGames/base/utils.py:19\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(game, agents, N)\u001b[0m\n\u001b[1;32m     17\u001b[0m game\u001b[39m.\u001b[39mreset()\n\u001b[1;32m     18\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m game\u001b[39m.\u001b[39mterminated():\n\u001b[0;32m---> 19\u001b[0m     action \u001b[39m=\u001b[39m agents[game\u001b[39m.\u001b[39;49magent_selection]\u001b[39m.\u001b[39;49maction()\n\u001b[1;32m     20\u001b[0m     game\u001b[39m.\u001b[39mstep(action)\n\u001b[1;32m     21\u001b[0m values\u001b[39m.\u001b[39mappend(game\u001b[39m.\u001b[39mreward(game\u001b[39m.\u001b[39magents[\u001b[39m0\u001b[39m]))\n",
      "File \u001b[0;32m~/Downloads/MA/AlternatingGames/agents/counterfactualregret.py:64\u001b[0m, in \u001b[0;36mCounterFactualRegret.action\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[39mreturn\u001b[39;00m a\n\u001b[1;32m     63\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mTrain agent before calling action()\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Train agent before calling action()"
     ]
    }
   ],
   "source": [
    "# Si falla al ejecutar con el error que hay que entrenar primero, hay que entrenar por más iteraciones\n",
    "run(game=game, agents=agents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game.reset()\n",
    "for agent in range(game.num_agents):\n",
    "    print(agents[game.agents[agent]].policy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
